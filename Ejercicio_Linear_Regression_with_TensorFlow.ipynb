{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8t1PaNQR6eGp"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy import optimize\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw = fetch_california_housing()\n",
        "X = pd.DataFrame(data=raw['data'], columns=raw['feature_names'])\n",
        "y = pd.Series(raw['target'])\n",
        "X\n",
        "y\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jx-BTNbKMUoB",
        "outputId": "d3a515bb-9c3e-4bc9-ab95-550ab9fb7468"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        4.526\n",
              "1        3.585\n",
              "2        3.521\n",
              "3        3.413\n",
              "4        3.422\n",
              "         ...  \n",
              "20635    0.781\n",
              "20636    0.771\n",
              "20637    0.923\n",
              "20638    0.847\n",
              "20639    0.894\n",
              "Length: 20640, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features = ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']\n",
        "scaler = StandardScaler()\n",
        "X[features] = scaler.fit_transform(X[features])\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "D6K5oSt-MgnA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the TensorFlow graph:\n",
        "* Create placeholders for the input features (X) and target variable (y).\n",
        "* Create variables for the model's weights (W) and bias (b).\n",
        "* Define the linear regression model using the equation: y_pred = X * W + b.\n",
        "* Define the loss function as the mean squared error between the predicted values and the true values.\n",
        "* Choose an optimizer (e.g., Gradient Descent) to minimize the loss function."
      ],
      "metadata": {
        "id": "BtelnBtaNZW-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.compat.v1.disable_eager_execution()\n",
        "X_placeholder = tf.compat.v1.placeholder(tf.float64, shape=[None, 8])\n",
        "y_placeholder = tf.compat.v1.placeholder(tf.float64,shape=[None])"
      ],
      "metadata": {
        "id": "WLdacMBMfTOi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "W = tf.Variable(tf.random.normal([X_train.shape[1], 1], dtype=tf.float64))\n",
        "b = tf.Variable(tf.random.normal([1], dtype=tf.float64))"
      ],
      "metadata": {
        "id": "mqEkRV41rHEk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred= tf.matmul(X_placeholder, W) + b"
      ],
      "metadata": {
        "id": "26SRvGH4sC3M"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = tf.reduce_mean(tf.square(y_pred - y_placeholder))\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_hm7viYsZNA",
        "outputId": "c5f27c0f-8043-4a61-e051-20cebc19fca5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'Mean:0' shape=() dtype=float64>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model:\n",
        "\n",
        "* Initialize TensorFlow session.\n",
        "* Initialize the model's variables.\n",
        "* Set the number of training epochs and the learning rate.\n",
        "* For each epoch, iterate through the training dataset and update the model's parameters using the optimizer.\n",
        "* Print the training loss at regular intervals.\n"
      ],
      "metadata": {
        "id": "hQsaAQGcxt4F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.optimizers.SGD(learning_rate=0.01)\n",
        "\n",
        "num_epochs = 4\n",
        "batch_size = 2\n",
        "total_batches = int(np.ceil(len(X_train) / batch_size))\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    epoch_loss = tf.keras.metrics.Mean()\n",
        "    epoch_accuracy = tf.keras.metrics.BinaryAccuracy()\n",
        "\n",
        "    for batch in range(total_batches):\n",
        "        start_index = batch * batch_size\n",
        "        end_index = start_index + batch_size\n",
        "\n",
        "        x_batch = X_train[start_index:end_index]\n",
        "        y_batch = y_train[start_index:end_index]\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred = tf.matmul(x_batch, W) + b\n",
        "            loss = tf.reduce_mean(tf.square(y_pred - y_batch))\n",
        "\n",
        "        gradients = tape.gradient(loss, [W, b])\n",
        "        optimizer.apply_gradients(zip(gradients, [W, b]))\n",
        "\n",
        "        epoch_loss(loss)\n",
        "        epoch_accuracy(y_batch, y_pred)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "    print(f\"Loss: {epoch_loss.result()}\")\n",
        "    print(f\"Accuracy: {epoch_accuracy.result()}\")\n",
        "\n",
        "    epoch_loss.reset_states()\n",
        "    epoch_accuracy.reset_states()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fFs5fa9ss6A",
        "outputId": "b60ca6ed-666b-4a18-edd8-f0575615f368"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "Loss: Tensor(\"Identity_33024:0\", shape=(), dtype=float32)\n",
            "Accuracy: Tensor(\"Identity_33025:0\", shape=(), dtype=float32)\n",
            "Epoch 2/4\n",
            "Loss: Tensor(\"Identity_66050:0\", shape=(), dtype=float32)\n",
            "Accuracy: Tensor(\"Identity_66051:0\", shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bHD1d0T5tAyv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}